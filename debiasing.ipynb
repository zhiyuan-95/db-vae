{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOq1T3boYy2Zo0up4gI+X0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhiyuan-95/db-vae/blob/main/debiasing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nSbzUg1DG3Ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005a84c4-3195-434c-8c08-7b641f53547c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/775.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m634.9/775.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.0/151.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m151.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml --quiet\n",
        "import comet_ml\n",
        "# TODO: ENTER YOUR API KEY HERE!! instructions above\n",
        "COMET_API_KEY = \"ROr5Iwf4PjYLL2ZhtmHtYHhoP\"\n",
        "\n",
        "# Import Tensorflow 2.0\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import IPython\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the training data: both images from CelebA and ImageNet\n",
        "path_to_training_data = tf.keras.utils.get_file('train_face.h5', 'https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1')\n",
        "# Instantiate a TrainingDatasetLoader using the downloaded dataset\n",
        "loader = mdl.lab2.TrainingDatasetLoader(path_to_training_data)"
      ],
      "metadata": {
        "id": "wknku3YlHBQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab79357-e334-4946-9b27-028483f3931b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1\n",
            "\u001b[1m1263889489/1263889489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n",
            "Opening /root/.keras/datasets/train_face.h5\n",
            "Loading data into memory...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a Comet experiment to track our training run ###\n",
        "def create_experiment(project_name, i):\n",
        "  # end any prior experiments\n",
        "  if 'experiment' in locals():\n",
        "    experiment.end()\n",
        "\n",
        "  # initiate the comet experiment for tracking\n",
        "  experiment = comet_ml.Experiment(\n",
        "                  api_key=COMET_API_KEY,\n",
        "                  project_name=project_name)\n",
        "  # log our hyperparameters, defined above, to the experiment\n",
        "  for param, value in params.items():\n",
        "    experiment.log_parameter(param, value[i])\n",
        "  experiment.flush()\n",
        "  return experiment"
      ],
      "metadata": {
        "id": "IfxrEs7CB_ht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the CNN model ###\n",
        "\n",
        "n_filters = 12 # base number of convolutional filters\n",
        "\n",
        "'''Function to define a standard CNN model'''\n",
        "def make_standard_classifier(n_outputs=1):\n",
        "  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Dense(n_outputs, activation=None),\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "standard_classifier = make_standard_classifier()"
      ],
      "metadata": {
        "id": "dhmRIyeYHCVM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the decoder portion of the DB-VAE ###\n",
        "\n",
        "n_filters = 12 # base number of convolutional filters, same as standard CNN\n",
        "latent_dim = 100 # number of latent variables\n",
        "\n",
        "def make_face_decoder_network(latent):\n",
        "  # Functionally define the different layer types we will use\n",
        "  Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "  Reshape = tf.keras.layers.Reshape\n",
        "\n",
        "  # Build the decoder network using the Sequential API\n",
        "  decoder = tf.keras.Sequential([\n",
        "    # Transform to pre-convolutional generation\n",
        "    Dense(units=4*4*6*n_filters),  # 4x4 feature maps (with 6N occurances)\n",
        "    Reshape(target_shape=(4, 4, 6*n_filters)),\n",
        "\n",
        "    # Upscaling convolutions (inverse of encoder)\n",
        "    Conv2DTranspose(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=2*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    Conv2DTranspose(filters=3, kernel_size=5,  strides=2),\n",
        "  ])\n",
        "\n",
        "  return decoder"
      ],
      "metadata": {
        "id": "YEhs7yIUUUJ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### VAE Reparameterization ###\n",
        "\n",
        "\"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "# Arguments\n",
        "    z_mean, z_logsigma (tensor): mean and log of varience of latent distribution (Q(z|X))\n",
        "# Returns\n",
        "    z (tensor): sampled latent vector\n",
        "\"\"\"\n",
        "def sampling(z_mean, z_logsigma):\n",
        "  # By default, random.normal is \"standard\" (ie. mean=0 and std=1.0)\n",
        "  z_logsigma = tf.clip_by_value(z_logsigma, -100, 3.0)\n",
        "  sigma = tf.exp(0.5*z_logsigma)\n",
        "  eps = tf.random.normal(tf.shape(sigma))\n",
        "  eps = tf.clip_by_value(eps, -3,3)\n",
        "  z = z_mean + sigma * eps\n",
        "  return z"
      ],
      "metadata": {
        "id": "cB44tBk1TYYc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Defining and creating the DB-VAE ###\n",
        "\n",
        "class DB_VAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(DB_VAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    # Define the number of outputs for the encoder. Recall that we have\n",
        "    # `latent_dim` latent variables, as well as a supervised output for the\n",
        "    # classification.\n",
        "    num_encoder_dims = 2*self.latent_dim + 1\n",
        "\n",
        "    self.encoder = make_standard_classifier(num_encoder_dims)\n",
        "    self.decoder = make_face_decoder_network(latent_dim)\n",
        "\n",
        "  # function to feed images into encoder, encode the latent space, and output\n",
        "  #   classification probability\n",
        "  def encode(self, x, training = False):\n",
        "    # encoder output\n",
        "    encoder_output = self.encoder(x, training = training)\n",
        "    # classification prediction\n",
        "    y_logit = tf.expand_dims(encoder_output[:, 0], -1)\n",
        "\n",
        "    # latent variable distribution parameters\n",
        "    z_mean = encoder_output[:, 1:self.latent_dim+1]\n",
        "    z_logsigma = encoder_output[:, self.latent_dim+1:]\n",
        "    return y_logit, z_mean, z_logsigma\n",
        "\n",
        "  # VAE reparameterization: given a mean and logsigma, sample latent variables\n",
        "  def reparameterize(self, z_mean, z_logsigma):\n",
        "    z = sampling(z_mean, z_logsigma)\n",
        "    return z\n",
        "\n",
        "  # Decode the latent space and output reconstruction\n",
        "  def decode(self, z, training = False):\n",
        "    reconstruction = self.decoder(z,training=training)\n",
        "    return reconstruction\n",
        "\n",
        "  # The call function will be used to pass inputs x through the core VAE\n",
        "  def call(self, x, training=False):\n",
        "    # Encode input to a prediction and latent space\n",
        "    y_logit, z_mean, z_logsigma = self.encode(x, training=training)\n",
        "    z = self.reparameterize(z_mean, z_logsigma)\n",
        "    recon = self.decode(z,training=training)\n",
        "    return y_logit, z_mean, z_logsigma, recon\n",
        "\n",
        "  # Predict face or not face logit for given input x\n",
        "  def predict(self, x):\n",
        "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
        "    return y_logit"
      ],
      "metadata": {
        "id": "VTuULo0DUfRY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE"
      ],
      "metadata": {
        "id": "ZMtVXR1lNX_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***vae loss fucntion***"
      ],
      "metadata": {
        "id": "gJ00o3qtTOEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Defining the VAE loss function ###\n",
        "\n",
        "def vae_loss_function(x, x_recon, mu, logsigma, c2, c3):\n",
        "\n",
        "  # L_(KL):  this examines how much the latent variables are close to unit normal distribution\n",
        "  # which means it forces the latent variable to get closer to the unit normal distribution\n",
        "  # and how much does it close to unit normal dis is depend on the kl_weight\n",
        "  KL_loss = tf.reduce_sum(tf.exp(0.5*logsigma) + tf.square(mu) - tf.ones_like(mu) - 0.5*logsigma, axis = 1)\n",
        "  # examine the difference between the output image and the input image\n",
        "  reconstruction_loss = tf.reduce_mean(tf.abs(x - x_recon), axis = [1,2,3])\n",
        "  vae_loss = c2*reconstruction_loss+c3*KL_loss\n",
        "  return vae_loss,c2*reconstruction_loss,c3*KL_loss"
      ],
      "metadata": {
        "id": "m4D1D-GyTSwh"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Loss function for DB-VAE ###\n",
        "def debiasing_loss_function(x, x_pred, y, y_logit, mu, logsigma, c, eps=1e-8):\n",
        "    vae_loss, recon, KL = vae_loss_function(x, x_pred, mu, logsigma, c[1], c[2])\n",
        "    classification_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_logit))\n",
        "    face_indicator = tf.cast(tf.equal(y, 1), tf.float32)\n",
        "    vae_loss = tf.expand_dims(vae_loss, axis = 0)\n",
        "    vae_loss_faces = vae_loss@face_indicator / (tf.reduce_sum(y) + eps)\n",
        "    total_loss = c[0]*classification_loss + vae_loss_faces[0][0]\n",
        "    return total_loss, classification_loss,vae_loss_faces[0][0], KL, recon"
      ],
      "metadata": {
        "id": "U-H_mmPYW-8g"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = loader.get_batch(10000)\n",
        "c = (1,0.2,0.0002)\n",
        "dbvae = DB_VAE(latent_dim)\n",
        "y_logit, z_mean, z_logsigma, x_recon = dbvae(x, training=True)\n",
        "loss, classification, vae_loss_faces,KL, recon = debiasing_loss_function(x, x_recon, y, y_logit, z_mean, z_logsigma,c)"
      ],
      "metadata": {
        "id": "yxwxUrS1fnRx"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5s4fBQ-2vj-X"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AfWRTcdlWWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DB-VAE architecture"
      ],
      "metadata": {
        "id": "_TjUjLyTUTSz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "o_580EAEsCNY"
      },
      "outputs": [],
      "source": [
        "def get_z(images, dbvae, batch_size = 1024):\n",
        "  N = images.shape[0]\n",
        "  z = np.zeros((N, dbvae.latent_dim))\n",
        "  for start_ind in range(0, N, batch_size):\n",
        "    end_ind = min(start_ind+batch_size, N+1)\n",
        "    batch = (images[start_ind:end_ind]).astype(np.float32)/255\n",
        "    y_logit, z_mean, z_logsigma = dbvae.encode(batch)\n",
        "    z_out = dbvae.reparameterize(z_mean, z_logsigma)\n",
        "    z[start_ind:end_ind] = z_out\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Resampling algorithm for DB-VAE ###\n",
        "\n",
        "'''Function that recomputes the sampling probabilities for images within a batch\n",
        "      based on how they distribute across the training data'''\n",
        "def get_training_sample_probabilities(images, dbvae, bins=10, smoothing_fac=0):\n",
        "    print(\"Recomputing the sampling probabilities\")\n",
        "    z = get_z(images, dbvae)\n",
        "    # sampling probabilities for the images, initialized to 1.0 for each image and latent dimension\n",
        "    training_sample_p = np.ones_like(z)\n",
        "\n",
        "    # consider the distribution for each latent variable\n",
        "    for i in range(dbvae.latent_dim):\n",
        "\n",
        "        latent_distribution = z[:,i]\n",
        "        # generate a histogram of the latent distribution\n",
        "        hist_density, bin_edges =  np.histogram(latent_distribution, density=True, bins=bins)\n",
        "\n",
        "        # we set the first(the smallest) element and last(the largest) element appeared in the set to -inf and inf|\n",
        "        bin_edges[0] = -float('inf')\n",
        "        bin_edges[-1] = float('inf')\n",
        "\n",
        "        # call the digitize function to find which bins in the latent distribution\n",
        "        # every data sample falls in to\n",
        "        #\n",
        "        bin_idx = np.digitize(z[:,i], bin_edges, right=True)\n",
        "\n",
        "        # smooth the density function\n",
        "        hist_smoothed_density = hist_density + smoothing_fac\n",
        "        hist_smoothed_density = hist_smoothed_density / np.sum(hist_smoothed_density)\n",
        "\n",
        "        # hist_smoothed_density[bin_idx-1] lookup operation to find the probability density associated with each mu\n",
        "        # invert the density function\n",
        "        p = 1.0/(hist_smoothed_density[bin_idx-1])\n",
        "\n",
        "        # normalize probabilities for the current latent dimension\n",
        "        p = p/np.sum(p)\n",
        "\n",
        "        # Assign probabilities to the corresponding column in training_sample_p\n",
        "        training_sample_p[:, i] = np.sqrt(p)\n",
        "\n",
        "  #  print(training_sample_p)\n",
        "    training_sample_p = tf.reduce_prod(training_sample_p, axis=1)\n",
        "    # final normalization of the combined probabilities\n",
        "    training_sample_p /= np.sum(training_sample_p)\n",
        "\n",
        "    return training_sample_p"
      ],
      "metadata": {
        "id": "RtI_o4n-Uod9"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zi3XPnz-smb6"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if the distribution is too extreme, then it means there are few data points going to have very large probability\n",
        "# which means the model will only focus on those minority points, which means it most like going to affect the perfomance of the model."
      ],
      "metadata": {
        "id": "0TcMGt4qBmZu"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_predicted_mean(model_forward_fn, val_groups, eps=1e-6):\n",
        "    group_means = []\n",
        "    for g in val_groups:\n",
        "        logits= model_forward_fn.predict(np.asarray(g, np.float32))\n",
        "        probs = tf.sigmoid(logits).numpy().reshape(-1)\n",
        "        group_means.append(float(np.mean(probs)))\n",
        "    return group_means\n",
        "\n",
        "def compute_validation(group_means):\n",
        "    predicted_mean = float(np.mean(group_means))\n",
        "    return predicted_mean\n",
        "\n",
        "def compute_db_validation(group_means):\n",
        "  gm = np.asarray(group_means, dtype=np.float64)\n",
        "  return float(np.max(gm) - np.min(gm))\n",
        "\n",
        "def validation(model_forward_fn, val_groups, eps=1e-6):\n",
        "  gm = compute_predicted_mean(model_forward_fn, val_groups)\n",
        "  val_score = compute_validation(gm)\n",
        "  db_val_score = compute_db_validation(gm)\n",
        "  del gm\n",
        "  return val_score, db_val_score"
      ],
      "metadata": {
        "id": "feoZon3THMyR"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EMASmoother:\n",
        "    def __init__(self, beta=0.90):\n",
        "        self.beta = beta\n",
        "        self.state = None\n",
        "    def update(self, x):\n",
        "        x = float(x)\n",
        "        self.state = x if self.state is None else self.beta*self.state + (1-self.beta)*x\n",
        "        return self.state\n",
        "\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3):\n",
        "        \"\"\"\n",
        "        patience: #epochs with no improvement allowed\n",
        "        min_delta: absolute (or relative if use_relative=True) improvement threshold\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.best_val = float(\"-inf\")   # higher is better\n",
        "        self.best_epoch = -1\n",
        "        self.bad_epochs = 0\n",
        "        self.should_stop = False\n",
        "\n",
        "    def update(self, val_score, epoch):\n",
        "        if val_score>self.best_val:\n",
        "            self.best_val = val_score\n",
        "            self.best_epoch = epoch\n",
        "            self.bad_epochs = 0\n",
        "        else:\n",
        "            self.bad_epochs += 1\n",
        "            if self.bad_epochs >= self.patience:\n",
        "                self.should_stop = True\n",
        "\n",
        "        return self.should_stop ,self.best_val,self.best_epoch\n"
      ],
      "metadata": {
        "id": "LKKYtSvbMXcw"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkAndLog(early, experiment, loss, val_score, dbval_score, epoch):\n",
        "  should_stop,best_val, best_epoch = early.update(val_score, epoch=epoch)\n",
        "  experiment.log_metric(\"loss_ema\",           loss,                 step=epoch)\n",
        "  experiment.log_metric(\"val\",            val_score,            step=epoch)\n",
        "  experiment.log_metric(\"dbval\",          dbval_score,          step=epoch)\n",
        "  experiment.log_metric('best_val',       best_val,              step=epoch)\n",
        "  experiment.log_metric('best_epoch',     best_epoch,              step=epoch)\n",
        "  return should_stop, best_epoch"
      ],
      "metadata": {
        "id": "ybMKP2V1Mcji"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training the DB-VAE ###\n",
        "num_expt = 20\n",
        "trial_per_expt = 3\n",
        "#validation set\n",
        "test_faces = mdl.lab2.get_test_faces()\n",
        "keys = [\"Light Female\", \"Light Male\", \"Dark Female\", \"Dark Male\"]\n",
        "epoch_max = 15\n",
        "# Hyperparameters\n",
        "bin = 10\n",
        "latent_dim = 100\n",
        "smoothing = 0.2 #, 0.6, 1\n",
        "c =(1,0.2,0.0002) # weight on classification loss, reconstruction loss, KL, loss\n",
        "params = dict(\n",
        "  batch_size = [random.choice([x for x in range(20,70,5)]) for _ in range(num_expt)],\n",
        "  learning_rate = [np.round(random.uniform(5e-5,1e-3),6)for _ in range(num_expt)],\n",
        "  smoothing_fact = [smoothing for _ in range(num_expt)]\n",
        ")\n",
        "for iter in range(num_expt):\n",
        "  for j in range(trial_per_expt):\n",
        "    total_loss,classification_loss, KL, recon, vae_loss_faces,eval = [],[],[],[],[],[]\n",
        "    experiment = create_experiment(f\"DBVAE_c{c}\", iter)\n",
        "    optimizer = tf.keras.optimizers.Adam(params[\"learning_rate\"][iter], clipnorm=1.0)\n",
        "    loss_history = mdl.util.LossHistory(smoothing_factor=0.99)\n",
        "    plotter = mdl.util.PeriodicPlotter(sec=18, scale='semilogy')\n",
        "    if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "    dbvae = DB_VAE(latent_dim)\n",
        "    @tf.function\n",
        "    def debiasing_train_step(x, y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_logit, z_mean, z_logsigma, x_recon = dbvae(x, training=True)\n",
        "            loss, classification,vae_loss, KL, recon = debiasing_loss_function(x, x_recon, y, y_logit, z_mean, z_logsigma,c)\n",
        "        grads = tape.gradient(loss, dbvae.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, dbvae.trainable_variables))\n",
        "        return loss, classification, vae_loss, KL, recon\n",
        "    all_faces = loader.get_all_train_faces()\n",
        "    early = EarlyStopper()\n",
        "\n",
        "    # The training loop -- outer loop iterates over the number of epochs\n",
        "    step = 0\n",
        "    for epoch in range(epoch_max):\n",
        "#      IPython.display.clear_output(wait=True)\n",
        "      loss_smoother = EMASmoother(beta=0.95)\n",
        "      p_faces = get_training_sample_probabilities(all_faces, dbvae,bins=bin, smoothing_fac=params['smoothing_fact'][iter])\n",
        "      # get a batch of training data and compute the training step\n",
        "      for idx in tqdm(range(loader.get_train_size()//params[\"batch_size\"][iter]),\n",
        "                  desc=f\" Expmt {iter+1}/{num_expt} |\"\n",
        "                  f\"Trial {j+1}/{trial_per_expt} |\"\n",
        "                  f\"Epoch {epoch+1}/{epoch_max} |\"\n",
        "                  f\"Smooth {params['smoothing_fact'][iter]} |\"\n",
        "                f\"BS={params['batch_size'][iter]} | LR={params['learning_rate'][iter]:.6f}\"):\n",
        "\n",
        "        # load a batch of data\n",
        "        (x, y) = loader.get_batch(params[\"batch_size\"][iter], p_pos=p_faces)\n",
        "        # loss optimization\n",
        "        loss, classification, vae , KL, recon= debiasing_train_step(x, y)\n",
        "        loss_smooth = loss_smoother.update(loss.numpy().mean())\n",
        "        loss_history.append(loss_smooth)\n",
        "        plotter.plot(loss_history.get())\n",
        "        if idx%20==0:\n",
        "          experiment.log_metric(\"loss\", loss, step=step)\n",
        "          experiment.log_metric('loss_smooth', loss_smooth, step=step)\n",
        "          experiment.log_metric('classification', classification, step=step)\n",
        "          experiment.log_metric('vae', vae, step=step)\n",
        "          experiment.log_metric('KL', np.mean(KL), step=step)\n",
        "          experiment.log_metric('recon', np.mean(recon), step=step)\n",
        "        step += 1\n",
        "        del x, y, loss, classification, KL, recon, vae , loss_smooth\n",
        "# regular validation and debiasing validation for every epoch\n",
        "      loss_ema = float(loss_history.get()[-1])\n",
        "      val_score, dbval_score = validation(dbvae, test_faces)\n",
        "# early stopping and log the experiments\n",
        "      should_stop, best_epoch = checkAndLog(early, experiment, loss_ema, val_score, dbval_score, epoch)\n",
        "      if should_stop:\n",
        "          print(f\"[EarlyStop] epoch={epoch+1} ; best_epoch={best_epoch+1}\")\n",
        "          break\n",
        "      del should_stop, best_epoch, loss_ema, val_score, dbval_score\n",
        "    del loss_history\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    experiment.end()"
      ],
      "metadata": {
        "id": "SiD88tmyWKEv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "acc6981c-2430-4c1b-a627-ed5f17f478c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " Expmt 1/20 |Trial 1/3 |Epoch 2/15 |Smooth 0.2 |BS=35 | LR=0.000163:  92%|█████████▏| 2899/3140 [00:48<00:05, 44.59it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WiLu_uWrQRs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9P2x9blOKSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}